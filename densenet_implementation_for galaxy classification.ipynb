{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkwQyzoGhOXz",
        "outputId": "9bdd2e6f-75f2-4ebc-997c-c42af6f76166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# Check for GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "# Set image dimensions and batch size\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Load dataset using ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the data from your paths\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/sdss_mobile/dataset_split/Train',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/sdss_mobile/dataset_split/Validation',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/sdss_mobile/dataset_split/Test',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Calculate class weights for imbalanced datasets\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Load DenseNet121 model\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers on top\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)  # Add dropout to reduce overfitting\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(3, activation='softmax')(x)  # 3 classes for classification\n",
        "\n",
        "# Build the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Save model checkpoint callback\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_model_densenet.keras',  # Filepath where the model will be saved\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    save_best_only=True,  # Save only the best model\n",
        "    mode='min',  # Save model when validation loss decreases\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Reduce learning rate callback\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Early stopping callback\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model with class weights\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[checkpoint, reduce_lr, early_stop]  # Add the callbacks here\n",
        ")\n",
        "\n",
        "# Unfreeze more layers for fine-tuning (start from layer 200)\n",
        "for layer in base_model.layers[:200]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model.layers[200:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile model with a lower learning rate for fine-tuning\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fine-tuning with more epochs\n",
        "fine_tune_epochs = 30  # Increase fine-tuning epochs\n",
        "total_epochs = 20 + fine_tune_epochs\n",
        "\n",
        "# Continue fine-tuning with model saving callbacks\n",
        "history_fine = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
        "    epochs=total_epochs,\n",
        "    initial_epoch=history.epoch[-1],\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[checkpoint, reduce_lr, early_stop]  # Add the callbacks here\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // BATCH_SIZE)\n",
        "print('Test accuracy:', test_acc)\n",
        "\n",
        "# Classification report and confusion matrix\n",
        "Y_pred = model.predict(test_generator, test_generator.samples // BATCH_SIZE + 1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(test_generator.classes, y_pred))\n",
        "\n",
        "print('Classification Report')\n",
        "target_names = ['Class 5 - Barred Spiral Galaxies', 'Class 6 - Unbarred Tight Spiral Galaxies', 'Class 7 - Unbarred Loose Spiral Galaxies']\n",
        "print(classification_report(test_generator.classes, y_pred, target_names=target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyjHGRBZsjUq",
        "outputId": "aa6b1451-63db-441b-e6d0-555e6d0b30ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Found 2479 images belonging to 3 classes.\n",
            "Found 460 images belonging to 3 classes.\n",
            "Found 650 images belonging to 3 classes.\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.5034 - loss: 0.9743 \n",
            "Epoch 1: val_loss improved from inf to 3.41294, saving model to best_model_densenet.keras\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m903s\u001b[0m 11s/step - accuracy: 0.5037 - loss: 0.9734 - val_accuracy: 0.2857 - val_loss: 3.4129 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.4375 - loss: 0.8263"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_loss did not improve from 3.41294\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 175ms/step - accuracy: 0.4375 - loss: 0.8263 - val_accuracy: 0.2500 - val_loss: 3.4496 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m76/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.5694 - loss: 0.8147\n",
            "Epoch 3: val_loss did not improve from 3.41294\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 385ms/step - accuracy: 0.5694 - loss: 0.8142 - val_accuracy: 0.3147 - val_loss: 3.5824 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 1.0488\n",
            "Epoch 4: val_loss did not improve from 3.41294\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.5000 - loss: 1.0488 - val_accuracy: 0.2500 - val_loss: 3.7639 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.5676 - loss: 0.7752\n",
            "Epoch 5: val_loss did not improve from 3.41294\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 380ms/step - accuracy: 0.5680 - loss: 0.7749 - val_accuracy: 0.3393 - val_loss: 3.7882 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.5938 - loss: 0.8104\n",
            "Epoch 6: val_loss improved from 3.41294 to 3.40306, saving model to best_model_densenet.keras\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5938 - loss: 0.8104 - val_accuracy: 0.4167 - val_loss: 3.4031 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.6104 - loss: 0.7258\n",
            "Epoch 7: val_loss did not improve from 3.40306\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 390ms/step - accuracy: 0.6103 - loss: 0.7259 - val_accuracy: 0.3772 - val_loss: 3.8389 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6875 - loss: 0.7029\n",
            "Epoch 8: val_loss did not improve from 3.40306\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - accuracy: 0.6875 - loss: 0.7029 - val_accuracy: 0.5000 - val_loss: 3.5051 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.6140 - loss: 0.7266\n",
            "Epoch 9: val_loss did not improve from 3.40306\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 383ms/step - accuracy: 0.6138 - loss: 0.7266 - val_accuracy: 0.3571 - val_loss: 3.8078 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5312 - loss: 0.8501\n",
            "Epoch 10: val_loss improved from 3.40306 to 2.52090, saving model to best_model_densenet.keras\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5312 - loss: 0.8501 - val_accuracy: 0.5833 - val_loss: 2.5209 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.5932 - loss: 0.7267\n",
            "Epoch 11: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 385ms/step - accuracy: 0.5932 - loss: 0.7266 - val_accuracy: 0.3371 - val_loss: 3.7967 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5625 - loss: 0.7931\n",
            "Epoch 12: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.5625 - loss: 0.7931 - val_accuracy: 0.2500 - val_loss: 4.5187 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.5998 - loss: 0.6922\n",
            "Epoch 13: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 382ms/step - accuracy: 0.6001 - loss: 0.6921 - val_accuracy: 0.3549 - val_loss: 3.8915 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8438 - loss: 0.4941\n",
            "Epoch 14: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.8438 - loss: 0.4941 - val_accuracy: 0.4167 - val_loss: 4.0384 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.5985 - loss: 0.6980\n",
            "Epoch 15: val_loss did not improve from 2.52090\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 376ms/step - accuracy: 0.5986 - loss: 0.6980 - val_accuracy: 0.3638 - val_loss: 3.9589 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5625 - loss: 0.6660\n",
            "Epoch 16: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.5625 - loss: 0.6660 - val_accuracy: 0.1667 - val_loss: 4.2799 - learning_rate: 2.0000e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.6242 - loss: 0.6656\n",
            "Epoch 17: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 380ms/step - accuracy: 0.6241 - loss: 0.6657 - val_accuracy: 0.3259 - val_loss: 3.9942 - learning_rate: 2.0000e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6875 - loss: 0.6523\n",
            "Epoch 18: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.6875 - loss: 0.6523 - val_accuracy: 0.3333 - val_loss: 3.7923 - learning_rate: 2.0000e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.6142 - loss: 0.6848\n",
            "Epoch 19: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 382ms/step - accuracy: 0.6142 - loss: 0.6847 - val_accuracy: 0.3371 - val_loss: 4.0116 - learning_rate: 2.0000e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.6875 - loss: 0.5398\n",
            "Epoch 20: val_loss did not improve from 2.52090\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.6875 - loss: 0.5398 - val_accuracy: 0.5000 - val_loss: 3.3162 - learning_rate: 2.0000e-05\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "Epoch 20/50\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6176 - loss: 0.7279\n",
            "Epoch 20: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 1s/step - accuracy: 0.6177 - loss: 0.7279 - val_accuracy: 0.3393 - val_loss: 3.9808 - learning_rate: 1.0000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.5938 - loss: 0.7469\n",
            "Epoch 21: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.5938 - loss: 0.7469 - val_accuracy: 0.2500 - val_loss: 4.3493 - learning_rate: 1.0000e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 0.6534 - loss: 0.6780\n",
            "Epoch 22: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 389ms/step - accuracy: 0.6537 - loss: 0.6776 - val_accuracy: 0.3326 - val_loss: 4.5182 - learning_rate: 1.0000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6875 - loss: 0.6163\n",
            "Epoch 23: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - accuracy: 0.6875 - loss: 0.6163 - val_accuracy: 0.3333 - val_loss: 3.9357 - learning_rate: 1.0000e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 0.6886 - loss: 0.6114\n",
            "Epoch 24: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 388ms/step - accuracy: 0.6889 - loss: 0.6111 - val_accuracy: 0.3393 - val_loss: 4.9450 - learning_rate: 1.0000e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7812 - loss: 0.6046\n",
            "Epoch 25: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.7812 - loss: 0.6046 - val_accuracy: 0.3333 - val_loss: 4.2481 - learning_rate: 1.0000e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.7496 - loss: 0.5219\n",
            "Epoch 26: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 385ms/step - accuracy: 0.7496 - loss: 0.5218 - val_accuracy: 0.3504 - val_loss: 5.0847 - learning_rate: 1.0000e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6875 - loss: 0.5529\n",
            "Epoch 27: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 0.6875 - loss: 0.5529 - val_accuracy: 0.3333 - val_loss: 6.1756 - learning_rate: 1.0000e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.7713 - loss: 0.4652\n",
            "Epoch 28: val_loss did not improve from 2.52090\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 382ms/step - accuracy: 0.7715 - loss: 0.4653 - val_accuracy: 0.3549 - val_loss: 5.2622 - learning_rate: 1.0000e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m 1/77\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8125 - loss: 0.3289\n",
            "Epoch 29: val_loss did not improve from 2.52090\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 0.8125 - loss: 0.3289 - val_accuracy: 0.4167 - val_loss: 5.6872 - learning_rate: 2.0000e-06\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 20.\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 13s/step - accuracy: 0.4452 - loss: 3.0274\n",
            "Test accuracy: 0.4609375\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 722ms/step\n",
            "Confusion Matrix\n",
            "[[100 105   0]\n",
            " [ 92  91   0]\n",
            " [142 120   0]]\n",
            "Classification Report\n",
            "                                          precision    recall  f1-score   support\n",
            "\n",
            "        Class 5 - Barred Spiral Galaxies       0.30      0.49      0.37       205\n",
            "Class 6 - Unbarred Tight Spiral Galaxies       0.29      0.50      0.36       183\n",
            "Class 7 - Unbarred Loose Spiral Galaxies       0.00      0.00      0.00       262\n",
            "\n",
            "                                accuracy                           0.29       650\n",
            "                               macro avg       0.20      0.33      0.25       650\n",
            "                            weighted avg       0.18      0.29      0.22       650\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}